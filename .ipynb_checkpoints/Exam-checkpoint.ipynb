{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a7f720d",
   "metadata": {},
   "source": [
    "1. Задан двухмерный массив ar1 размерности (10, 10), состоящий из случайных целых чисел в пределах от 0 до 15. Вычислить разность s_odd - s_even, где s_odd - сумма элементов, стоящих на позиции (x, y), где (x + y) является нечетным числом; s_even - сумма элементов, стоящих на позиции (x, y), где (x + y) является четным числом.\n",
    "\n",
    "Решить задачу средствами numpy и/или pandas. Не использовать циклы и конструкции стандартного Python там, где можно использовать возможности данных библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b58f56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f6b58ffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n"
     ]
    }
   ],
   "source": [
    "a = np.random.randint(0, 15, (10, 10))\n",
    "b = pd.DataFrame(a)\n",
    "my_list = [1, 3]\n",
    "mask = [[1 if x % 2 == 0 else 0 for x in range(y, 10+y)] for y in range(10)]\n",
    "c = pd.DataFrame(mask)\n",
    "s_even = b*c\n",
    "s_even = s_even.sum().sum()\n",
    "s_odd = b.sum().sum() - s_even\n",
    "print(s_odd-s_even)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb50105",
   "metadata": {},
   "source": [
    "2. С помощью кода на Python с использованием sqlite3 и SQL решить задачу. Реализовать функции на Python:\n",
    "    1. Которая возвращает все имеющиеся жанры. \n",
    "    2. Которая возвращает ID жанров, в которых написано более 100 треков, и их (жанров) название."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "4b83027d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "62ca4a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "con = sqlite3.connect(\"Chinook_Sqlite.sqlite\")\n",
    "c = con.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "3889fe7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Album',), ('Artist',), ('Customer',), ('Employee',), ('Genre',), ('Invoice',), ('InvoiceLine',), ('MediaType',), ('Playlist',), ('PlaylistTrack',), ('Track',)]\n"
     ]
    }
   ],
   "source": [
    "c.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "print(c.fetchall())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "607e3bec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Rock', 'Jazz', 'Metal', 'Alternative & Punk', 'Rock And Roll', 'Blues', 'Latin', 'Reggae', 'Pop', 'Soundtrack', 'Bossa Nova', 'Easy Listening', 'Heavy Metal', 'R&B/Soul', 'Electronica/Dance', 'World', 'Hip Hop/Rap', 'Science Fiction', 'TV Shows', 'Sci Fi & Fantasy', 'Drama', 'Comedy', 'Alternative', 'Classical', 'Opera']\n"
     ]
    }
   ],
   "source": [
    "def get1(c):\n",
    "    res = c.execute(\"SELECT * FROM Genre\").fetchall()\n",
    "    return [res[i][1] for i in range(len(res))]\n",
    "print(get1(c))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "29849727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 'Rock'), (2, 'Jazz'), (3, 'Metal'), (4, 'Alternative & Punk'), (7, 'Latin')]\n"
     ]
    }
   ],
   "source": [
    "def get2(c):\n",
    "    a = c.execute(\"SELECT Count(*), GenreId FROM Track GROUP BY GenreId\").fetchall()\n",
    "    return([c.execute(f\"SELECT * FROM Genre where GenreId = {i[1]}\").fetchone() for i in a if i[0] > 100])\n",
    "print(get2(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "303c3b63",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('GenreId', None, None, None, None, None, None),\n",
       " ('Name', None, None, None, None, None, None))"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.execute(\"SELECT * FROM Genre\").description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b51c71",
   "metadata": {},
   "source": [
    "3. Датасет: album_artist.xlsx\n",
    "С помощью кода на Python с использованием xlwings решить задачу. Вынести названия артистов на отдельный лист \"Артисты\" и присвоить каждому артисту уникальный идентификатор. Заменить названия артистов на исходном листе на идентификаторы с листа \"Артисты\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "aaab0474",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xlwings as xw\n",
    "from xlwings.constants import AutoFillType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "14926e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "wb = xw.Book(\"album_artist.xlsx\")\n",
    "sh = wb.sheets['Sheet1']\n",
    "un_art = set(sh.range(\"D2:D348\").value)\n",
    "# wb.sheets.add('Артисты')\n",
    "sh2 = wb.sheets['Артисты']\n",
    "sh2.range('B1').options(transpose=True).value = [i for i in range(1, len(un_art)+1)]\n",
    "sh2.range('A1').options(transpose=True).value = list(un_art)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "675bf18e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sh.range('E2').options(transpose=True).formula = '=VLOOKUP(D2,Артисты!$A$1:$B$204,2,0)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "2dfb1373",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xw.Range('E2').api.AutoFill(xw.Range(\"E2:E348\").api, AutoFillType.xlFillDefault)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "797755c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sh.range('D2').options(transpose=True).value = sh.range('E2:E348').options(transpose=True).value\n",
    "sh.range('E2:E348').options(transpose=True).value = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac29e155",
   "metadata": {},
   "source": [
    "4. Датасет: us-countries.csv\n",
    "Создайте таблицу, где по строкам располагаются названия штатов, по столбцам - каждый из 12 месяцев 2020 года, а в ячейках таблицы хранится суммарное количество смертей в данном штате в этот месяц. Если информация за какой-то месяц отсутствует, укажите в этой ячейке значение 0.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e63cca70",
   "metadata": {},
   "outputs": [],
   "source": [
    "us = pd.read_csv('us-counties.csv', parse_dates=['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cffe8001",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>county</th>\n",
       "      <th>state</th>\n",
       "      <th>fips</th>\n",
       "      <th>cases</th>\n",
       "      <th>deaths</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-21</td>\n",
       "      <td>Snohomish</td>\n",
       "      <td>Washington</td>\n",
       "      <td>53061.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>Snohomish</td>\n",
       "      <td>Washington</td>\n",
       "      <td>53061.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-23</td>\n",
       "      <td>Snohomish</td>\n",
       "      <td>Washington</td>\n",
       "      <td>53061.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-24</td>\n",
       "      <td>Cook</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>17031.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-24</td>\n",
       "      <td>Snohomish</td>\n",
       "      <td>Washington</td>\n",
       "      <td>53061.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2089614</th>\n",
       "      <td>2022-01-06</td>\n",
       "      <td>Sweetwater</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>56037.0</td>\n",
       "      <td>8471</td>\n",
       "      <td>110.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2089615</th>\n",
       "      <td>2022-01-06</td>\n",
       "      <td>Teton</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>56039.0</td>\n",
       "      <td>6836</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2089616</th>\n",
       "      <td>2022-01-06</td>\n",
       "      <td>Uinta</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>56041.0</td>\n",
       "      <td>4245</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2089617</th>\n",
       "      <td>2022-01-06</td>\n",
       "      <td>Washakie</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>56043.0</td>\n",
       "      <td>1908</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2089618</th>\n",
       "      <td>2022-01-06</td>\n",
       "      <td>Weston</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>56045.0</td>\n",
       "      <td>1261</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2089619 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              date      county       state     fips  cases  deaths\n",
       "0       2020-01-21   Snohomish  Washington  53061.0      1     0.0\n",
       "1       2020-01-22   Snohomish  Washington  53061.0      1     0.0\n",
       "2       2020-01-23   Snohomish  Washington  53061.0      1     0.0\n",
       "3       2020-01-24        Cook    Illinois  17031.0      1     0.0\n",
       "4       2020-01-24   Snohomish  Washington  53061.0      1     0.0\n",
       "...            ...         ...         ...      ...    ...     ...\n",
       "2089614 2022-01-06  Sweetwater     Wyoming  56037.0   8471   110.0\n",
       "2089615 2022-01-06       Teton     Wyoming  56039.0   6836    14.0\n",
       "2089616 2022-01-06       Uinta     Wyoming  56041.0   4245    34.0\n",
       "2089617 2022-01-06    Washakie     Wyoming  56043.0   1908    39.0\n",
       "2089618 2022-01-06      Weston     Wyoming  56045.0   1261    16.0\n",
       "\n",
       "[2089619 rows x 6 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "66e56d17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>date</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>county</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Abbeville</th>\n",
       "      <td>31.432432</td>\n",
       "      <td>32.785714</td>\n",
       "      <td>25.113636</td>\n",
       "      <td>19.366667</td>\n",
       "      <td>20.500000</td>\n",
       "      <td>20.500000</td>\n",
       "      <td>21.548387</td>\n",
       "      <td>25.129032</td>\n",
       "      <td>27.550000</td>\n",
       "      <td>31.564516</td>\n",
       "      <td>34.866667</td>\n",
       "      <td>37.838710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Acadia</th>\n",
       "      <td>182.621622</td>\n",
       "      <td>179.392857</td>\n",
       "      <td>141.463415</td>\n",
       "      <td>98.016667</td>\n",
       "      <td>103.435484</td>\n",
       "      <td>113.266667</td>\n",
       "      <td>124.532258</td>\n",
       "      <td>150.241935</td>\n",
       "      <td>164.216667</td>\n",
       "      <td>173.500000</td>\n",
       "      <td>180.366667</td>\n",
       "      <td>191.903226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accomack</th>\n",
       "      <td>38.729730</td>\n",
       "      <td>33.642857</td>\n",
       "      <td>26.069767</td>\n",
       "      <td>20.350000</td>\n",
       "      <td>25.145161</td>\n",
       "      <td>28.866667</td>\n",
       "      <td>30.129032</td>\n",
       "      <td>32.274194</td>\n",
       "      <td>39.650000</td>\n",
       "      <td>46.354839</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>52.580645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ada</th>\n",
       "      <td>462.729730</td>\n",
       "      <td>424.785714</td>\n",
       "      <td>274.860000</td>\n",
       "      <td>231.733333</td>\n",
       "      <td>244.016129</td>\n",
       "      <td>250.566667</td>\n",
       "      <td>261.274194</td>\n",
       "      <td>298.209677</td>\n",
       "      <td>352.716667</td>\n",
       "      <td>437.516129</td>\n",
       "      <td>509.633333</td>\n",
       "      <td>575.661290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adair</th>\n",
       "      <td>30.452703</td>\n",
       "      <td>28.901786</td>\n",
       "      <td>25.451613</td>\n",
       "      <td>18.635593</td>\n",
       "      <td>20.701613</td>\n",
       "      <td>21.550000</td>\n",
       "      <td>21.903226</td>\n",
       "      <td>23.504032</td>\n",
       "      <td>26.320833</td>\n",
       "      <td>29.455645</td>\n",
       "      <td>33.350000</td>\n",
       "      <td>38.834677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Yukon-Koyukuk Census Area</th>\n",
       "      <td>4.648649</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.033898</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.080645</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>2.733333</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>5.822581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Yuma</th>\n",
       "      <td>346.527027</td>\n",
       "      <td>385.625000</td>\n",
       "      <td>290.625000</td>\n",
       "      <td>210.966667</td>\n",
       "      <td>214.540323</td>\n",
       "      <td>228.133333</td>\n",
       "      <td>259.782258</td>\n",
       "      <td>292.112903</td>\n",
       "      <td>308.450000</td>\n",
       "      <td>318.104839</td>\n",
       "      <td>327.183333</td>\n",
       "      <td>356.395161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zapata</th>\n",
       "      <td>21.729730</td>\n",
       "      <td>24.035714</td>\n",
       "      <td>29.193548</td>\n",
       "      <td>18.581818</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>18.274194</td>\n",
       "      <td>20.048387</td>\n",
       "      <td>22.333333</td>\n",
       "      <td>25.419355</td>\n",
       "      <td>27.116667</td>\n",
       "      <td>27.532258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zavala</th>\n",
       "      <td>31.945946</td>\n",
       "      <td>34.107143</td>\n",
       "      <td>40.870968</td>\n",
       "      <td>29.318182</td>\n",
       "      <td>20.580645</td>\n",
       "      <td>20.500000</td>\n",
       "      <td>22.080645</td>\n",
       "      <td>26.322581</td>\n",
       "      <td>32.200000</td>\n",
       "      <td>35.209677</td>\n",
       "      <td>37.866667</td>\n",
       "      <td>40.177419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ziebach</th>\n",
       "      <td>8.702703</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>4.894737</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>5.161290</td>\n",
       "      <td>6.916667</td>\n",
       "      <td>8.725806</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1854 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "date                               1           2           3           4   \\\n",
       "county                                                                      \n",
       "Abbeville                   31.432432   32.785714   25.113636   19.366667   \n",
       "Acadia                     182.621622  179.392857  141.463415   98.016667   \n",
       "Accomack                    38.729730   33.642857   26.069767   20.350000   \n",
       "Ada                        462.729730  424.785714  274.860000  231.733333   \n",
       "Adair                       30.452703   28.901786   25.451613   18.635593   \n",
       "...                               ...         ...         ...         ...   \n",
       "Yukon-Koyukuk Census Area    4.648649    4.000000    4.000000    2.033898   \n",
       "Yuma                       346.527027  385.625000  290.625000  210.966667   \n",
       "Zapata                      21.729730   24.035714   29.193548   18.581818   \n",
       "Zavala                      31.945946   34.107143   40.870968   29.318182   \n",
       "Ziebach                      8.702703    9.000000    9.000000    9.000000   \n",
       "\n",
       "date                               5           6           7           8   \\\n",
       "county                                                                      \n",
       "Abbeville                   20.500000   20.500000   21.548387   25.129032   \n",
       "Acadia                     103.435484  113.266667  124.532258  150.241935   \n",
       "Accomack                    25.145161   28.866667   30.129032   32.274194   \n",
       "Ada                        244.016129  250.566667  261.274194  298.209677   \n",
       "Adair                       20.701613   21.550000   21.903226   23.504032   \n",
       "...                               ...         ...         ...         ...   \n",
       "Yukon-Koyukuk Census Area    2.000000    2.000000    2.080645    2.500000   \n",
       "Yuma                       214.540323  228.133333  259.782258  292.112903   \n",
       "Zapata                      18.000000   18.000000   18.274194   20.048387   \n",
       "Zavala                      20.580645   20.500000   22.080645   26.322581   \n",
       "Ziebach                      4.894737    4.500000    4.500000    4.500000   \n",
       "\n",
       "date                               9           10          11          12  \n",
       "county                                                                     \n",
       "Abbeville                   27.550000   31.564516   34.866667   37.838710  \n",
       "Acadia                     164.216667  173.500000  180.366667  191.903226  \n",
       "Accomack                    39.650000   46.354839   50.000000   52.580645  \n",
       "Ada                        352.716667  437.516129  509.633333  575.661290  \n",
       "Adair                       26.320833   29.455645   33.350000   38.834677  \n",
       "...                               ...         ...         ...         ...  \n",
       "Yukon-Koyukuk Census Area    2.733333    3.500000    4.400000    5.822581  \n",
       "Yuma                       308.450000  318.104839  327.183333  356.395161  \n",
       "Zapata                      22.333333   25.419355   27.116667   27.532258  \n",
       "Zavala                      32.200000   35.209677   37.866667   40.177419  \n",
       "Ziebach                      4.500000    5.161290    6.916667    8.725806  \n",
       "\n",
       "[1854 rows x 12 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "us.pivot_table('deaths', 'county', pd.DatetimeIndex(us['date']).month, fill_value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62b293d",
   "metadata": {},
   "source": [
    "5. По данным из файла data/meals.json сформировать словарь, в котором по идентификатору блюда можно получить список ингредиентов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9c655ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ead594a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Chicken Thighs',\n",
       " 'Challots',\n",
       " 'Ginger',\n",
       " 'Garlic Clove',\n",
       " 'Cayenne Pepper',\n",
       " 'Turmeric',\n",
       " 'Cumin',\n",
       " 'Coriander',\n",
       " 'Fennel',\n",
       " 'Tamarind Paste',\n",
       " 'Coconut Milk',\n",
       " 'Sugar',\n",
       " 'Water']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('meals.json', 'r') as f:\n",
    "    cs = json.load(f)\n",
    "res = {}\n",
    "for i in cs['meals']:\n",
    "    ls = []\n",
    "    for n in range(1, 22):\n",
    "        if i.get(f'strIngredient{n}', False):\n",
    "            ls.append(i[f'strIngredient{n}'])\n",
    "        else:\n",
    "            res.setdefault(i['idMeal'], ls)\n",
    "            ls=[]\n",
    "            break\n",
    "            \n",
    "res.get('53050')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3209e7f3",
   "metadata": {},
   "source": [
    "6. Датасет: Womens Clothing E-Commerce Reviews.csv\n",
    "Для каждого уникального значения в столбце Division Name найти топ-5 самых часто используемых слов в описании отзыва. Исключить из рассмотрения стоп-слова.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "60a1db25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\OlegPC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\OlegPC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "bbe75bd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Division Name</th>\n",
       "      <th>Review Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>General</td>\n",
       "      <td>love this dress!  it's sooo pretty.  i happene...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>General Petite</td>\n",
       "      <td>i love, love, love this jumpsuit. it's fun, fl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Initmates</td>\n",
       "      <td>absolutely wonderful - silky and sexy and comf...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Division Name                                        Review Text\n",
       "0         General  love this dress!  it's sooo pretty.  i happene...\n",
       "1  General Petite  i love, love, love this jumpsuit. it's fun, fl...\n",
       "2       Initmates  absolutely wonderful - silky and sexy and comf..."
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wom = pd.read_csv('Womens Clothing E-Commerce Reviews.csv', index_col=[0])\n",
    "wom.dtypes\n",
    "wom['Review Text'] = wom['Review Text'].astype(str)\n",
    "wom['Review Text'] = wom['Review Text'].str.lower()\n",
    "a6 = wom.groupby(['Division Name'])['Review Text'].apply('; '.join).reset_index()\n",
    "a6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "8a55d575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "General\n",
      "6018 - dress\n",
      "5317 - love\n",
      "5159 - size\n",
      "4524 - top\n",
      "4384 - fit\n",
      "General Petite\n",
      "4275 - dress\n",
      "3099 - love\n",
      "3035 - size\n",
      "2486 - top\n",
      "2476 - fit\n",
      "Initmates\n",
      "518 - love\n",
      "504 - size\n",
      "419 - like\n",
      "411 - fit\n",
      "406 - wear\n"
     ]
    }
   ],
   "source": [
    "res = []\n",
    "for i in a6['Review Text'].tolist():\n",
    "    words_d = {}\n",
    "    for j in [word for word in nltk.word_tokenize(i) if word.isalpha()]:\n",
    "        words_d.setdefault(j, 0)\n",
    "        words_d[j] += 1  \n",
    "    res.append(words_d)\n",
    "    words_d = {}\n",
    "k = 0\n",
    "ch = 0\n",
    "for y in res:\n",
    "    print(a6['Division Name'].tolist()[ch])\n",
    "    for w in sorted(y, key=y.get, reverse=True):\n",
    "        if w not in stopwords.words('english'):\n",
    "            print(f\"{y[w]} - {w}\")\n",
    "            k+=1\n",
    "        if k == 5:\n",
    "            k = 0\n",
    "            ch += 1\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd26ce7",
   "metadata": {},
   "source": [
    "7. Датасет: people.*.csv\n",
    "В people.*.csv найти номера карт, сумма цифр в которых кратна 7. Выполнить задание с использованием Dask, распараллелив процесс обработки данных. Выполнить задание с использованием Dask (корректным!), распараллелив процесс обработки данных (использование Dask должно приводить к истинной параллельной обработке данных).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "07a2ea6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "import dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "a13785e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def krat_7(f):\n",
    "    if sum(int(i) for i in f if i.isdigit()) % 7 == 0:\n",
    "        return f\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "def read(fl):    \n",
    "    ddf = dd.read_csv(fl)\n",
    "    return list(ddf['card'].map(krat_7).dropna().compute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "4398fe83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 146 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i in range(3):\n",
    "    read(f'people.{i}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "4a034d32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 128 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "l = []\n",
    "for i in range(3):\n",
    "    l.append(dask.delayed(read)(f'people.{i}.csv'))\n",
    "l = dask.compute(*l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "04a04f10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3.99 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "l = dask.compute(*l)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6df91fd",
   "metadata": {},
   "source": [
    "8. Подсчитать, сколько раз во всех текстовых файлах, лежащих в каталоге fish, встречаются слова, начинающиеся с прописной буквы. Выполнить задание с использованием Dask, распараллелив процесс обработки данных. Выполнить задание с использованием Dask (корректным!), распараллелив процесс обработки данных (использование Dask должно приводить к истинной параллельной обработке данных)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "af78f5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read2(txt): \n",
    "    with open(txt, 'r', encoding=\"utf8\") as file:\n",
    "        data = file.read().replace('\\n\\t', ' ')\n",
    "        words_d = {}\n",
    "        for j in [word for word in nltk.word_tokenize(data) if word[0].isupper()]:\n",
    "            words_d.setdefault(j, 0)\n",
    "            words_d[j] += 1\n",
    "    return words_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "88cb500c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 131 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i in range(1, 5):\n",
    "    read2(f'00{i}.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "e429297b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 80.7 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "l2 = []\n",
    "for i in range(1, 5):\n",
    "    l2.append(dask.delayed(read2)(f'00{i}.txt'))\n",
    "l2 = dask.compute(*l2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b42e354",
   "metadata": {},
   "source": [
    "9. Сгенерируйте 10 строк длиной в 10000 символов, состоящих из маленьких английских букв. Посчитайте, сколько раз в этих 10 строках встречается шаблон \"x?y?z\", где знак вопроса обозначает один любой символ. Решение этой задачи распараллелить, используя multiprocessing Pool. Сравнить продолжительность последовательного и параллельного решения задачи."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d2bb6ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import choice\n",
    "from string import ascii_lowercase\n",
    "import re\n",
    "\n",
    "def f9(s):\n",
    "    return len(re.findall(r'x.y.z', s))\n",
    "    \n",
    "a9 = [''.join(choice(ascii_lowercase) for i in range(10000)) for _ in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d6e41b53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "Wall time: 997 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "s9 = 0\n",
    "for i in a9:\n",
    "    s9 += f9(i)\n",
    "print(s9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e1de98df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import choice\n",
    "from string import ascii_lowercase\n",
    "import re\n",
    "import time\n",
    "from multiprocessing import Pool\n",
    "\n",
    "def f9(s):\n",
    "    return len(re.findall(r'x.y.z', s))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    a9 = [''.join(choice(ascii_lowercase) for i in range(10000)) for _ in range(10)]\n",
    "    start = time.time()\n",
    "    s9 = 0\n",
    "    for i in a9:\n",
    "        s9 += f9(i)\n",
    "    print(s9)\n",
    "    end = time.time()\n",
    "    print((end - start) * 1000000)\n",
    "\n",
    "    start = time.time()\n",
    "    pool = Pool(processes=2)\n",
    "    print(sum(pool.map(f9, a9)))\n",
    "    end = time.time()\n",
    "    print((end - start) * 1000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46fd3640",
   "metadata": {},
   "source": [
    "10. Создайте dask.array размерности 10 тыс на 5, заполненный случайными целыми числами на отрезке [0, 10]. Создайте версию этого массива, оставив только строки, в которых есть число 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "e23b52d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9, 5, 4, 1, 7],\n",
       "       [7, 4, 7, 6, 8],\n",
       "       [3, 7, 5, 4, 3],\n",
       "       ...,\n",
       "       [7, 2, 9, 8, 4],\n",
       "       [0, 2, 1, 4, 7],\n",
       "       [6, 7, 9, 5, 8]])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dask.array as da\n",
    "x = da.random.randint(0, 10, size=(10000, 5))\n",
    "x[da.any(x == 7, axis = 1)].compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31a54d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
